# SVM

SVM is a supervised machine learning algorithm that can be used for both classification and regression tasks, but it’s primarily used for classification. The main goal of SVM is to find the best boundary (or hyperplane) that separates different classes in the data.

	1. Hyperplane:
	  
      In SVM, a hyperplane is the decision boundary that separates different classes. For example, in 2D space, the hyperplane is a line, and in 3D space, it’s a plane. The goal is to find the hyperplane that best separates the classes.

  2. Margin:

      The margin is the distance between the hyperplane and the closest data points from each class. SVM tries to maximize this margin to ensure that the decision boundary is as far as possible from the data points of both classes. A larger margin generally means better generalization to unseen data.
  
3. Support Vectors:
      
      The support vectors are the data points that lie closest to the hyperplane. These points are critical because they define the position of the hyperplane. Removing other points won’t affect the hyperplane, but moving these support vectors will.

4. Kernel Trick:
      
      In cases where the data is not linearly separable, SVM uses a technique called the kernel trick. This transforms the data into a higher-dimensional space where it becomes easier to separate with a hyperplane.
